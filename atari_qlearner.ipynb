{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from model import DeepQNetwork, Agent\n",
    "import numpy as np\n",
    "import time\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain loaded\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('SpaceInvaders-v0')\n",
    "brain = Agent(gamma=0.95, epsilon=1.0,\n",
    "              alpha=0.003, maxMemorySize=1000,\n",
    "              replace=None)\n",
    "\n",
    "brain.Q_eval.state_dict(torch.load(\"/home/plicca/Documents/code/atari/model/qeval\"))\n",
    "brain.Q_next.state_dict(torch.load(\"/home/plicca/Documents/code/atari/model/qnext\"))\n",
    "brain.memory = pickle.load(open('/home/plicca/Documents/code/atari/model/mem.npy', 'rb'))\n",
    "\n",
    "print(\"Brain loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "epsHistory = []\n",
    "numGames = 50\n",
    "batch_size = 16\n",
    "done = False\n",
    "env = gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting game  1 epsilon: 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plicca/miniconda3/envs/atari/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "/home/plicca/miniconda3/envs/atari/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480.0 ::: 71.91035100000227\n",
      "starting game  2 epsilon: 0.0500\n",
      "205.0 ::: 38.39864499999749\n",
      "starting game  3 epsilon: 0.0500\n",
      "225.0 ::: 63.877502999999706\n",
      "starting game  4 epsilon: 0.0500\n",
      "300.0 ::: 43.21649500000058\n",
      "starting game  5 epsilon: 0.0500\n",
      "175.0 ::: 36.20476200000121\n",
      "starting game  6 epsilon: 0.0500\n",
      "800.0 ::: 115.60747199999969\n",
      "starting game  7 epsilon: 0.0500\n",
      "150.0 ::: 36.022892999997566\n",
      "starting game  8 epsilon: 0.0500\n",
      "255.0 ::: 69.11289100000067\n",
      "starting game  9 epsilon: 0.0500\n",
      "155.0 ::: 37.82827600000019\n",
      "starting game  10 epsilon: 0.0500\n",
      "155.0 ::: 40.028487999999925\n",
      "starting game  11 epsilon: 0.0500\n"
     ]
    }
   ],
   "source": [
    "for i in range(numGames):\n",
    "    print('starting game ', i + 1, 'epsilon: %.4f' % brain.EPSILON)\n",
    "    epsHistory.append(brain.EPSILON)\n",
    "    observation = env.reset()\n",
    "    frames = [np.sum(observation[15:200,30:125], axis=2)]\n",
    "    score = 0\n",
    "    lastAction = 0\n",
    "    delta = time.clock()\n",
    "    done = False\n",
    "    while not done:\n",
    "        if len(frames) == 3:\n",
    "            action = brain.chooseAction(frames)\n",
    "            frames = []\n",
    "            #current_time = time.clock()\n",
    "            #print(current_time - delta)\n",
    "            #delta = current_time\n",
    "        else:\n",
    "            action = lastAction\n",
    "        #env.render()\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        frames.append(np.sum(observation_[15:200,30:125], axis=2))\n",
    "        if done and info['ale.lives'] == 0:\n",
    "            reward = -100\n",
    "        brain.storeTransition(np.mean(observation[15:200,30:125], axis=2), action, reward,\n",
    "                              np.mean(observation_[15:200,30:125], axis=2))\n",
    "        observation = observation_\n",
    "\n",
    "        brain.learn(batch_size)\n",
    "        lastAction = action\n",
    "    print(score, ':::', time.clock() - delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(brain.Q_eval.state_dict(), \"/home/plicca/Documents/code/atari/model/qeval\")\n",
    "torch.save(brain.Q_next.state_dict(), \"/home/plicca/Documents/code/atari/model/qnext\")\n",
    "pickle.dump(brain.memory, open(\"/home/plicca/Documents/code/atari/model/mem.npy\", 'wb'))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
